<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Jean  Kaddour | publications</title>
<meta name="description" content="PhD Student in Machine Learning">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Jean</span>   Kaddour
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="paml" class="col-sm-8">
    
      <div class="title">Probabilistic Active Meta-Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  SÃ¦mundsson, SteindÃ³r,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Deisenroth, Marc
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper/2020/file/ef0d17b3bdb4ee2aa741ba28c7255c53-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/JeanKaddour/PAML" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      <a href="https://www.youtube.com/watch?v=ipN-bK6Od3U" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
      
      <a href="/assets/pdf/paml_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddour2021graph" class="col-sm-8">
    
      <div class="title">Causal Effect Inference for Structured Treatments</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhu, Yuchen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Qi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kusner, Matt J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Ricardo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2106.01939.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/JeanKaddour/GIN" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      <a href="https://www.youtube.com/watch?v=lnVDe1TbkbQ" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
      
      <a href="/assets/pdf/sin_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddour2022stop" class="col-sm-8">
    
      <div class="title">Stop Wasting My Time! Saving Days of ImageNet and BERT Training with Latest Weight Averaging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Kaddour, Jean</em>
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Has it Trained Yet? NeurIPS 2022 Workshop</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://openreview.net/pdf?id=0OrABUHZuz" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/JeanKaddour/LAWA" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddour2022causal" class="col-sm-8">
    
      <div class="title">Causal Machine Learning: A Survey and Open Problems</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lynch, Aengus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Qi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kusner, Matt J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Ricardo
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2206.15475.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://www.causal-machine-learning.com/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddour2022when" class="col-sm-8">
    
      <div class="title">When Do Flat Minima Optimizers Work?</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Linqing,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Silva, Ricardo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kusner, Matt
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://openreview.net/pdf?id=vDeh2yxTvuh" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddourNoTrainNo2023a" class="col-sm-8">
    
      <div class="title">No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Key, Oscar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nawrot, Piotr,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Minervini, Pasquale,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kusner, Matt J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2307.06440.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/jeankaddour/notrainnogain" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="wangEvaluatingSelfSupervisedLearning2023" class="col-sm-8">
    
      <div class="title">Evaluating Self-Supervised Learning for Molecular Graph Embeddings</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Wang, Hanchen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liu, Shengchao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tang, Jian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lasenby, Joan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liu, Qi
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2206.08005.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/hansen7/MolGraphEval" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Graph Self-Supervised Learning (GSSL) provides a robust pathway for acquiring embeddings without expert labelling, a capability that carries profound implications for molecular graphs due to the staggering number of potential molecules and the high cost of obtaining labels. However, GSSL methods are designed not for optimisation within a specific domain but rather for transferability across a variety of downstream tasks. This broad applicability complicates their evaluation. Addressing this challenge, we present â€™Molecular Graph Representation Evaluationâ€™ (MOLGRAPHEVAL), generating detailed profiles of molecular graph embeddings with interpretable and diversified attributes. MOLGRAPHEVAL offers a suite of probing tasks grouped into three categories: (i) generic graph, (ii) molecular substructure, and (iii) embedding space properties. By leveraging MOLGRAPHEVAL to benchmark existing GSSL methods against both current downstream datasets and our suite of tasks, we uncover significant inconsistencies between inferences drawn solely from existing datasets and those derived from more nuanced probing. These findings suggest that current evaluation methodologies fail to capture the entirety of the landscape.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddourChallengesApplicationsLarge2023" class="col-sm-8">
    
      <div class="title">Challenges and Applications of Large Language Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Harris, Joshua,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mozes, Maximilian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bradley, Herbie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Raileanu, Roberta,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and McHardy, Robert
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2307.10169.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the fieldâ€™s current state more quickly and become productive.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="lynch2023spawrious" class="col-sm-8">
    
      <div class="title">Spawrious: A benchmark for fine control of spurious correlation biases</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Lynch, Aengus,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dovonon, GbÃ¨tondji JS,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Silva, Ricardo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2303.05470</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2303.05470.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://aengusl.github.io/spawrious.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kaddourMiniPileChallengeDataEfficient2023" class="col-sm-8">
    
      <div class="title">The MiniPile Challenge for Data-Efficient Language Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Kaddour, Jean</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="http://arxiv.org/abs/2304.08442" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://huggingface.co/datasets/JeanKaddour/minipile" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using \k\-means, and (3) filter out low-quality clusters. To verify MiniPileâ€™s suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only \1.9}%\/\2.5}% on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on \2.6\x/\745\x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="zantedeschi2023dag" class="col-sm-8">
    
      <div class="title">DAG Learning on the Permutahedron</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Zantedeschi, Valentina,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Franceschi, Luca,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Kaddour, Jean</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kusner, Matt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Niculae, Vlad
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The Eleventh International Conference on Learning Representations </em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://openreview.net/pdf?id=m9LCdYgN8-6" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2023 Jean  Kaddour.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
